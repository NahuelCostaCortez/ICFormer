{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import utils\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy.interpolate import PchipInterpolator as pchip\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as rmse, mean_absolute_percentage_error as mape, pairwise_distances, r2_score\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prognosis dataset** \n",
    "\n",
    "Consists of duty cycles with one voltage curve for every 200 cycles (one every 10 cycles for cycles 1-200)\n",
    "\n",
    "\n",
    "There is a diagnostic dataset containing all possible degradations for the simulated cells. Each duty cycle of the prognostic dataset is constructed from a selection on the evolution of the voltage curves, which are obtained from the diagnostic dataset.\n",
    "\n",
    "\n",
    "Data structures:\n",
    "- cyc: array, 35 cycles\n",
    "\t- cycles from 0 to 200 with a step of 10 (21)\n",
    "\t- cycles from 200 to 3000 with a step of 200 (15)\n",
    "- Q: array, 1001 samples. Capacity curve.\n",
    "- QL: array, num_prognosis_samples x 35 cycles\n",
    "- V: array, num_diagnosis_samples x 1001. Voltage curves (from the diagnosis dataset).\n",
    "- indexes: array, num_prognosis_samples samples x 35 cycles. This array contains for every pair (sample, cycle) the index of the diagnosis dataset where the sample is. If the capacity loss associated with the sample exceeds 80% of the initial capacity, the index is negative (nan)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples:  127662\n"
     ]
    }
   ],
   "source": [
    "chemistry = 'LFP' # 'LFP', 'NCA' or 'NMC'\n",
    "\n",
    "cyc = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, \n",
    "400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800, 3000] # cycles for which there is data\n",
    "# as the cycles are not equally spaced, we need to select the cycles we want to use\n",
    "selected_cycles = [0, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800, 3000]\n",
    "# the index of the selected cycles are looked up in the original array\n",
    "selected_cycles_index = np.array([np.where(np.array(cyc)==el)[0][0] for el in selected_cycles])\n",
    "\n",
    "# --------------------- Indices to get data from diagnosis dataset --------------------\n",
    "indices = utils.read_mat('../data/'+chemistry+'/Vi.mat')['Vi'][:,selected_cycles_index] # indices where to look for the voltage curve in the diagnosis dataset\n",
    "indices = indices - 1 # in matlab, indices start at 1, in python they start at 0\n",
    "indices = indices.astype(np.int32) # change dtype of indices to int -> now nans are negative numbers\n",
    "    \n",
    "print(\"Total samples: \", indices.shape[0])\n",
    "\n",
    "# ----------------- Degradation modes and capacity loss---------------\n",
    "degradations = utils.read_mat('../data/'+chemistry+'/path_prognosis.mat')['path_prognosis'].T[:,selected_cycles_index]\n",
    "degradation_modes = degradations[:,:,0:3].astype(np.float32)\n",
    "QL = degradations[:,:,3].astype(np.float32)\n",
    "QL[QL==0] = 80 # needed in order to check if the QL is increasing\n",
    "QL[:,0] = 0 # there is not any capacity loss in the first cycle\n",
    "assert indices.shape[0] == QL.shape[0] == degradation_modes.shape[0]\n",
    "\n",
    "# --------------- Voltage and Capacity --------------\n",
    "V = utils.read_mat_hdf5('../data/'+chemistry+'/volt.mat', 'volt')\n",
    "Q = utils.read_mat(\"../data/Q.mat\")['Qnorm'].flatten()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Remove duplicated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples after removing duplicates:  66097\n"
     ]
    }
   ],
   "source": [
    "# some samples are duplicated\n",
    "_, unique_indices = np.unique(indices, return_index=True, axis=0) # remove duplicates\n",
    "indices = indices[unique_indices]\n",
    "QL = QL[unique_indices]\n",
    "degradation_modes = degradation_modes[unique_indices]\n",
    "print(\"Total samples after removing duplicates: \", indices.shape[0])\n",
    "assert indices.shape[0] == QL.shape[0] == degradation_modes.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Remove samples that gain capacity over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples after removing samples that gain capacity:  65958\n"
     ]
    }
   ],
   "source": [
    "# some samples gain capacity over time, we remove them\n",
    "valid_indices = utils.get_increasing_samples(QL)\n",
    "indices = indices[valid_indices]\n",
    "QL = QL[valid_indices]\n",
    "degradation_modes = degradation_modes[valid_indices]\n",
    "print(\"Total samples after removing samples that gain capacity: \", indices.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calculate IC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IC_curves = utils.retrieve_curves(chemistry, indices, V, Q)\n",
    "\n",
    "# Calculate the minimum and maximum values\n",
    "min_val = np.min(IC_curves)\n",
    "max_val = np.max(IC_curves)\n",
    "\n",
    "# Normalize using the minimum and maximum values\n",
    "IC_curves = (IC_curves - min_val) / (max_val - min_val)\n",
    "\n",
    "assert indices.shape[0] == QL.shape[0] == degradation_modes.shape[0] == IC_curves.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Label knees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_labels = utils.label_knees(QL, degradation_modes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Apply sliding windows and get pairs X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size_cycle = 800 # number of cycles to use for the windows size\n",
    "# get position of selected cycles where cycle = window_size_cycle\n",
    "window_size = selected_cycles.index(window_size_cycle) + 1\n",
    "\n",
    "x_ICs = []\n",
    "y_degradation_modes = []\n",
    "y_QLs = []\n",
    "y_knees = []\n",
    "sample_index = []\n",
    "\n",
    "num_samples, num_cycles, series_len = IC_curves.shape\n",
    "\n",
    "for sample_num in range(10): # this takes long, just illustrates what happens with the first 10 samples\n",
    "    for cycle_num in range(num_cycles-window_size+1):\n",
    "        ICs_cur = IC_curves[sample_num, cycle_num:cycle_num+window_size, :]\n",
    "        degradation_modes_cur = degradation_modes[sample_num, cycle_num:cycle_num+window_size, :]\n",
    "        QLs_cur = QL[sample_num, cycle_num:cycle_num+window_size]\n",
    "        knee_cur = knee_labels[sample_num][cycle_num:cycle_num+window_size]\n",
    "        # if any of the degradation modes is nan or degradation is 0.8 or there is no IC curve skip the sample\n",
    "        if np.any(np.isnan(degradation_modes_cur)) or np.any(QLs_cur == 80) or np.any(ICs_cur == 0.0):\n",
    "            break\n",
    "        else:\n",
    "            x_ICs.append(ICs_cur)\n",
    "            y_degradation_modes.append(degradation_modes_cur)\n",
    "            y_QLs.append(QLs_cur)\n",
    "            y_knees.append(knee_cur)\n",
    "            sample_index.append(sample_num)\n",
    "\n",
    "x_ICs = np.array(x_ICs)\n",
    "y_degradation_modes = np.array(y_degradation_modes)\n",
    "y_QLs = np.array(y_QLs)\n",
    "y_knees = np.array(y_knees)\n",
    "sample_index = np.array(sample_index)\n",
    "assert x_ICs.shape[0] == y_degradation_modes.shape[0] == y_QLs.shape[0] == y_knees.shape[0] == sample_index.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Remove samples in which the IC curves are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 5, 128)\n",
      "(28, 5, 3)\n",
      "(28, 5)\n",
      "(28, 5)\n",
      "(28,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "_, unique_indices = np.unique(x_ICs, return_index=True, axis=0)\n",
    "# update the arrays\n",
    "x_ICs = x_ICs[unique_indices]\n",
    "y_degradation_modes = y_degradation_modes[unique_indices]\n",
    "y_QLs = y_QLs[unique_indices]\n",
    "y_knees= y_knees[unique_indices]\n",
    "sample_index = sample_index[unique_indices]\n",
    "print(x_ICs.shape)\n",
    "print(y_degradation_modes.shape)\n",
    "print(y_QLs.shape)\n",
    "print(y_knees.shape)\n",
    "print(sample_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemistry = 'LFP' # 'LFP', 'NCA' or 'NMC'\n",
    "selected_cycles = [0, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800, 3000]\n",
    "\n",
    "with h5py.File('../data/'+chemistry+'/datasets.h5', 'r') as h5f:\n",
    "    # Load the first dataset\n",
    "    first_dataset = h5f['dataset_pre']\n",
    "    IC_curves = first_dataset['IC_curves'][()]\n",
    "    QLs = first_dataset['QLs'][()]\n",
    "    degradation_modes = first_dataset['degradation_modes'][()]\n",
    "\n",
    "    second_dataset = h5f['dataset']\n",
    "    x_ICs_train = second_dataset['x_ICs_train'][()]\n",
    "    y_degradation_modes_train = second_dataset['y_degradation_modes_train'][()]\n",
    "    y_QLs_train = second_dataset['y_QLs_train'][()]\n",
    "    y_silent_modes_train = second_dataset['y_silent_modes_train'][()].astype(int)\n",
    "    sample_index_train = second_dataset['sample_index_train'][()]\n",
    "\n",
    "#del(first_dataset)\n",
    "#del(second_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187702, 5, 128)\n",
      "(187702, 5, 3)\n",
      "(187702,)\n"
     ]
    }
   ],
   "source": [
    "chemistry = 'LFP'\n",
    "path = '../data/'+chemistry\n",
    "    \n",
    "with h5py.File(path+'/datasets.h5', 'r') as h5f:\n",
    "\tfirst_dataset = h5f['dataset_pre']\n",
    "\tnorm_values = first_dataset['norm_values'][()]\n",
    "\tmin_val = norm_values[0]\n",
    "\tmax_val = norm_values[1]\n",
    "\n",
    "\tdataset = h5f['dataset']\n",
    "\tx_train = dataset['x_ICs_train'][()]\n",
    "\ty_regression_train = dataset['y_degradation_modes_train'][()]\n",
    "\ty_classification_train = dataset['y_silent_modes_train'][()].astype(np.float32)\n",
    "del(first_dataset)\n",
    "del(dataset)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_regression_train.shape)\n",
    "print(y_classification_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f867e4773a5d549f6b33974196549f54f953cbb6ad5c913ab3ce9ac160f6abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
